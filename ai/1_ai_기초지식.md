## 1. ai 에 대해서


### RAG (검색 증강 생성)
- 대규모 언어 모델(LLM)이 훈련 데이터 외에 외부 지식 베이스에서 관련 정보를 검색하여 더 정확하고 최신 정보를 반영한 응답을 생성하도록 하는 기술
- 이 기술은 LLM의 환각(할루시네이션)을 줄이고 사용자의 질문에 대해 더 맞춤화되고 검증 가능한 답변을 제공하는 데 유용하며, 챗봇, 검색, 실시간 데이터 요약 등 다양한 분야에 적용

- 작동 방식
1. 외부 데이터 생성
- LLM의 원래 학습 데이터 세트 외부에 있는 새 데이터를 외부 데이터라고 합니다. 
- API, 데이터베이스 또는 문서 리포지토리와 같은 여러 데이터 소스에서 가져올 수 있습니다. 
- 데이터의 형식은 파일, 데이터베이스 레코드 또는 긴 형식의 텍스트와 같이 다양합니다. 
- 임베딩 언어 모델이라고 하는 또 다른 AI 기법은 데이터를 수치로 변환하고 벡터 데이터베이스에 저장합니다. 
- 이 프로세스는 생성형 AI 모델이 이해할 수 있는 지식 라이브러리를 생성

2. 검색 (Retrieval)
- 연관성 검색을 수행하는 단계는 다음과 같습니다. 
- 사용자 쿼리는 벡터 표현으로 변환되고 벡터 데이터베이스와 매칭됩니다. 
- 예를 들어 조직의 인사 관련 질문에 답변할 수 있는 스마트 챗봇을 생각할 수 있습니다. 
- 직원이 “연차휴가는 얼마나 남았나요?“라고 검색하면 시스템은 개별 직원의 과거 휴가 기록과 함께 연차 휴가 정책 문서를 검색합니다. 
- 이러한 특정 문서는 직원이 입력한 내용과 관련이 높기에 반환됩니다. 수학적 벡터 계산 및 표현을 사용하여 연관성이 계산 및 설정됩니다.

3. 증강(Augmentation)
- RAG 모델은 검색된 관련 데이터를 컨텍스트에 추가하여 사용자 입력(또는 프롬프트)을 보강합니다. 
- 이 단계에서는 프롬프트 엔지니어링 기술을 사용하여 LLM과 효과적으로 통신합니다. 
- 확장된 프롬프트를 사용하면 대규모 언어 모델이 사용자 쿼리에 대한 정확한 답변을 생성할 수 있습니다.

4. 생성(Generation)
    - LLM은 제공된 외부 정보와 자체 훈련된 지식을 바탕으로 더 정확하고 구체적인 응답을 생성합니다. 

    

